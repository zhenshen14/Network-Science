{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Project 2</center>\n",
    "### *Evgeniya Shevchuk*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we recreated two models: SIRS and SIR.\n",
    "\n",
    "Number of time steps - 30. Quantity of intially infected people - 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method that was used here is simply vaccinate 10% of nodes with the highest node degree as far as other strategies did not work. I also tried using highest node degree method after some steps (5% at the beginning of epidemics, next 5% on the 4th step when we know who is already infected) but the results were worse than this method. If we vaccinate infected node, then it gets the immunity for the further steps after he gets susceptible again.\n",
    "\n",
    "Despite we do 5 runs, the results are still random, so on further runs, results could be slightly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PLOS [dataset](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1001109#s2) of sexual escort market. It contains buyers as well as sellers of escort services. Contains about 15.000 nodes. As it is the real-world dataset, is it interesting to test a epidemic model on it. Use SIRS model- modification of SIR model, as 'recovering' nodes return to susceptible population after some time. Also, modify model to count recovery in days, not probabilistically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import csv\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from operator import itemgetter\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse.linalg as lg\n",
    "from numpy.linalg import lstsq\n",
    "import numpy as np\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = open('Dataset_S1.csv','rt')\n",
    "reader = csv.reader(dat,delimiter=';')\n",
    "Dset = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph(directed=False)\n",
    "edgelist = []\n",
    "for i in range(len(Dset)):\n",
    "    if i>=24:\n",
    "        edgelist.append((Dset[i][0],Dset[i][1]))\n",
    "g.add_edges_from(edgelist)\n",
    "g = list(nx.connected_component_subgraphs(g))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below example of use SIRS model - modification of SIR model, as our 'recovering' nodes return to susceptible population after some time.\n",
    "We also modify model to count recovery in days, not probabilistically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "   \\begin{cases}\n",
    "   \\cfrac{ds_i(t)}{dt} = -\\beta s_i(t)\\sum\\limits_j A_{ij} x_j(t) + \\gamma r_i(t) \\\\ \n",
    "   \\cfrac{dx_i(t)}{dt} = \\beta s_i(t)\\sum\\limits_j A_{ij} x_j(t) - \\gamma x_i(t)\\\\\n",
    "   \\cfrac{dr_i(t)}{dt} = \\gamma x_i(t) - \\gamma r_i(t)\n",
    "  \\end{cases}\n",
    "  \\\\\n",
    "  x_i(t) + s_i(t) + r_i(t) = 1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default parameters for Epidemic modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating sorted adjacency matrix to iterate\n",
    "#it is sorted by node degree-will be used later\n",
    "nodelist = g.nodes()\n",
    "deg = dict(nx.degree(g))\n",
    "sorted_deg = sorted(deg.items(),key=itemgetter(1),reverse=True)\n",
    "sortlist =[a[0]for a in sorted_deg]\n",
    "A = np.array(nx.adjacency_matrix(g,nodelist = sortlist).todense())\n",
    "n = len(nodelist) #total quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining randomiser for infection spread\n",
    "#also choosing number of initially infected individuals\n",
    "idx = np.random.choice(len(nodelist),50)\n",
    "I = np.zeros(len(nodelist))\n",
    "R = np.zeros(len(nodelist))\n",
    "S = np.ones(len(nodelist))\n",
    "I[idx]=1\n",
    "S[idx]=0\n",
    "def lottery(y,alph):\n",
    "    V = np.zeros(len(y))\n",
    "    for i in range(len(y)):\n",
    "        x = random.random()\n",
    "        if x < (1-(1-alph)**y[i]):\n",
    "            V[i] = 1\n",
    "        else:\n",
    "            V[i] = 0\n",
    "    return V\n",
    "\n",
    "del nodelist, deg, sorted_deg,sortlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our iterative epidemic function, based on model\n",
    "def epidemic_SIRS(bet,gam,delt,R,I,S,A,T):\n",
    "    t=1\n",
    "    rnd = list()\n",
    "    R = np.zeros(len(I))\n",
    "    M = np.zeros(len(I)) # for counting totally infected people\n",
    "    di = I\n",
    "    while t <=T:\n",
    "        if t == 1:  # on the first step we found top 10% of nodes and vaccinate them\n",
    "            V = np.zeros(len(I))\n",
    "            vac = int(n*0.1)\n",
    "            V[vac:] = 1   # for not vacinated\n",
    "        D = csr_matrix(A)*csr_matrix(np.diag(S))\n",
    "        ss_matr = (csr_matrix(I)*D).todense().tolist()[0]\n",
    "        ds = lottery(R,delt)\n",
    "        dr = lottery(I,gam)\n",
    "        di = lottery(ss_matr,bet)*V  # here we multiply it to the vaccinated vector value by value\n",
    "        dI = np.subtract(di,dr)\n",
    "        dS = np.subtract(ds,di)\n",
    "        dR = np.subtract(dr,ds)\n",
    "        I = I+dI\n",
    "        S = S+dS\n",
    "        R = R+dR\n",
    "        M = M+I\n",
    "        rn = [sum(I),sum(S),sum(R)]\n",
    "        rnd.append([round(x/len(I),2) for x in rn])\n",
    "        t+=1\n",
    "    total = n - (np.count_nonzero(M)) # counting how many nodes were never infected\n",
    "    return(total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Three competition scenarios for model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [] # for each scenario we do 5 runs to average it somehow, however the computation takes quite much time\n",
    "for i in range(5):\n",
    "    T1 = epidemic_SIRS(0.3,0.1,0.1,R,I,S,A,30)\n",
    "    s.append(T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = []\n",
    "for i in range(5):\n",
    "    T2 = epidemic_SIRS(0.2,0.5,0.2,R,I,S,A,30)\n",
    "    s2.append(T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = []\n",
    "for i in range(5):\n",
    "    T3 = epidemic_SIRS(0.7,0.05,0.5,R,I,S,A,30)\n",
    "    s3.append(T3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.mean(s)\n",
    "t2 = np.mean(s2)\n",
    "t3 = np.mean(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we compute and review different ways the infection can spread, given different parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epidemic_SIR(bet,gam,R,I,S,A,T):\n",
    "    t=1\n",
    "    rnd = list()\n",
    "    R = np.zeros(len(I))\n",
    "    M = np.zeros(len(I)) \n",
    "    di = I\n",
    "    while t <=T:\n",
    "        if t == 1:\n",
    "            V = np.zeros(len(I))\n",
    "            vac = int(n*0.1)\n",
    "            V[vac:] = 1   \n",
    "        D = csr_matrix(A)*csr_matrix(np.diag(S))\n",
    "        ss_matr = (csr_matrix(I)*D).todense().tolist()[0]\n",
    "        dr = lottery(I,gam)\n",
    "        di = lottery(ss_matr,bet)*V\n",
    "        dI = np.subtract(di,dr)\n",
    "        dS = -di\n",
    "        dR = dr\n",
    "        I = I+dI\n",
    "        S = S+dS\n",
    "        R = R+dR\n",
    "        M = M+I\n",
    "        rn = [sum(I),sum(S),sum(R)]\n",
    "        rnd.append([round(x/len(I),2) for x in rn])\n",
    "        t+=1\n",
    "    total = n - (np.count_nonzero(M))\n",
    "    return(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = []\n",
    "for i in range(5):\n",
    "    T4_h =(epidemic_SIR(0.2,0.1,R,I,S,A,3))\n",
    "    s4.append(T4_h)\n",
    "t4 = np.mean(s4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = []\n",
    "for i in range(5):\n",
    "    T4_h3 =(epidemic_SIR(0.2,0.1,R,I,S,A,5))\n",
    "    s5.append(T4_h3)\n",
    "t5 = np.mean(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s6 = []\n",
    "for i in range(5):\n",
    "    T4_h2 =(epidemic_SIR(0.2,0.1,R,I,S,A,10))\n",
    "    s6.append(T4_h2)\n",
    "t6 = np.mean(s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14302.633333333331"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av = (t1+t2+t3+t4+t5+t6)/6  #average value\n",
    "av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "list1 = ['1','2','3','4','5','6']\n",
    "list2 = [t1,t2,t3,t4,t5,t6]\n",
    "data = dict(col1=list1, col2=list2)\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('results1.csv',header=['id','score'],index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is not the most efficient since it takes quite a lot of time to compute. But still the results are pretty good and hard to beat with the small improvements that I have tried."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
